# -*- coding: utf-8 -*-
"""Parkinson's handwrititng .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3EhHoD3vo1QFhwQ7jXFKu8MTTDa58ia
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

df1=pd.read_csv("/content/drive/MyDrive/Parkinson's disease dtection/Meander_HandPD.csv")
df2=pd.read_csv("/content/drive/MyDrive/Parkinson's disease dtection/Spiral_HandPD.csv")

df1.shape

df2.shape

df1.columns

df2.columns

df1.head()

df2.head()

df1.shape
df1.columns
df1.describe()

df2.shape
df2.columns
df2.describe()

# Check for missing values
print(df1.isnull().sum())

print(df2.isnull().sum())

meander_cleaned = df1.drop(columns=["IMAGE_NAME"])
# One-hot encoding for categorical variables
meander_encoded = pd.get_dummies(meander_cleaned, columns=["GENDER", "RIGH/LEFT-HANDED"], drop_first=True)

# Separate features and target
meander_features = meander_encoded.drop(columns=["CLASS_TYPE", "_ID_EXAM", "ID_PATIENT"])
meander_target = meander_encoded["CLASS_TYPE"]

# Handle NaN values
meander_features = meander_features.fillna(meander_features.mean())



# Train-test split
X_train_meander, X_test_meander, y_train_meander, y_test_meander = train_test_split(
    meander_features, meander_target, test_size=0.2, random_state=42
)

from sklearn.preprocessing import StandardScaler

# Scale features for Meander dataset
scaler = StandardScaler()
X_train_meander_scaled = scaler.fit_transform(X_train_meander)
X_test_meander_scaled = scaler.transform(X_test_meander)

# Train and evaluate models for Meander dataset
print("\nTraining models for Meander dataset:")
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "SVM": SVC(random_state=42),
    "KNN": KNeighborsClassifier(),
}

from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize SMOTE
smote = SMOTE(sampling_strategy='auto', random_state=42)

# Apply SMOTE to the training data
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_meander_scaled, y_train_meander)

# Train and evaluate models
for name, model in models.items():
    # Train the model on the balanced dataset
    model.fit(X_train_balanced, y_train_balanced)

    # Make predictions on the test set
    y_pred = model.predict(X_test_meander_scaled)

    # Evaluate the model
    print(f"{name} Accuracy: {accuracy_score(y_test_meander, y_pred):.2f}")
    print(f"{name} Classification Report:\n{classification_report(y_test_meander, y_pred)}")
    print(f"{name} Confusion Matrix:\n{confusion_matrix(y_test_meander, y_pred)}\n")

# Correlation heatmap for Meander dataset
plt.figure(figsize=(12, 10))
sns.heatmap(meander_features.corr(), annot=False, cmap='coolwarm')
plt.title("Correlation Heatmap - Meander")
plt.show()

# Histograms for Meander dataset
meander_features.hist(bins=20, figsize=(14, 10))
plt.suptitle("Feature Distributions - Meander")
plt.show()

spiral_cleaned = df2.drop(columns=["IMAGE_NAME"])
spiral_encoded = pd.get_dummies(spiral_cleaned, columns=["GENDER", "RIGH/LEFT-HANDED"], drop_first=True)

# Separate features and target
spiral_features = spiral_encoded.drop(columns=["CLASS_TYPE", "_ID_EXAM", "ID_PATIENT"])
spiral_target = spiral_encoded["CLASS_TYPE"]

# Handle NaN values
spiral_features = spiral_features.fillna(spiral_features.mean())

# Train-test split
X_train_spiral, X_test_spiral, y_train_spiral, y_test_spiral = train_test_split(
    spiral_features, spiral_target, test_size=0.2, random_state=42
)

# Scale features for Spiral dataset
X_train_spiral_scaled = scaler.fit_transform(X_train_spiral)
X_test_spiral_scaled = scaler.transform(X_test_spiral)

from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize SMOTE
smote = SMOTE(sampling_strategy='auto', random_state=42)

# Apply SMOTE to the Spiral training dataset
X_train_spiral_balanced, y_train_spiral_balanced = smote.fit_resample(X_train_spiral_scaled, y_train_spiral)

# Train and evaluate models for the Spiral dataset
print("\nTraining models for Spiral dataset:")
for name, model in models.items():
    # Train the model on the balanced dataset
    model.fit(X_train_spiral_balanced, y_train_spiral_balanced)

    # Make predictions on the test set
    y_pred = model.predict(X_test_spiral_scaled)

    # Evaluate the model
    print(f"{name} Accuracy: {accuracy_score(y_test_spiral, y_pred):.2f}")
    print(f"{name} Classification Report:\n{classification_report(y_test_spiral, y_pred)}")
    print(f"{name} Confusion Matrix:\n{confusion_matrix(y_test_spiral, y_pred)}\n")

# Correlation heatmap for Spiral dataset
plt.figure(figsize=(12, 10))
sns.heatmap(spiral_features.corr(), annot=False, cmap='coolwarm')
plt.title("Correlation Heatmap - Spiral")
plt.show()

# Histograms for Spiral dataset
spiral_features.hist(bins=20, figsize=(14, 10))
plt.suptitle("Feature Distributions - Spiral")
plt.show()