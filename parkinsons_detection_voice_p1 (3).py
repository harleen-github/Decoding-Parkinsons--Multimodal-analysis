# -*- coding: utf-8 -*-
"""Parkinsons detection voice p1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZrErfqny9phGW17qknk0L8l2CFUny7j
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neural_network import MLPClassifier

# Import the 'files' object from 'google.colab'
from google.colab import files

df = pd.read_csv("/content/drive/MyDrive/Parkinson's disease dtection/parkinsons voice oxford.data", delimiter=",")

df.head()

df.shape

df.columns

print(df.isnull().sum())



print(df.isnull().sum())

print(df.dtypes)

df.columns = df.columns.str.replace(" ", "_").str.lower()





df = df.drop_duplicates()

df.describe()

X = df.drop(columns=['name', 'status'])
y = df['status']

# Drop non-numeric columns for correlation calculation
numeric_data = df.drop(columns=['name'])

# Compute the correlation matrix
plt.figure(figsize=(12, 8))
correlation_matrix = numeric_data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Histograms for feature distributions
df.hist(bins=15, figsize=(15, 12), color="skyblue", edgecolor="black")
plt.suptitle("Histograms of Features", fontsize=16)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)



# Step 4: Standardize the feature values
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = {

    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM": SVC(random_state=42, probability=True),
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "MLP": MLPClassifier(random_state=42, max_iter=300, hidden_layer_sizes=(100,))
}

results = {}

from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize SMOTE
smote = SMOTE(random_state=42)

# Apply SMOTE to the training data
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# Train and evaluate models
results = {}

for model_name, model in models.items():
    # Train the model on the balanced data
    model.fit(X_train_balanced, y_train_balanced)

    # Make predictions
    y_pred = model.predict(X_test_scaled)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    results[model_name] = accuracy

    print(f"{model_name}:\nAccuracy: {accuracy:.4f}\n")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("-" * 50)

for model_name, model in models.items():
    # Train the model
    model.fit(X_train_scaled, y_train)
    # Make predictions
    y_pred = model.predict(X_test_scaled)
    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    results[model_name] = accuracy
    print(f"{model_name}:\nAccuracy: {accuracy:.4f}\n")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("-" * 50)

plt.figure(figsize=(12, 6))
sns.barplot(x=list(results.keys()), y=list(results.values()))
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.xlabel("Models")
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Create a figure for the confusion matrices with enough space for all models
fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Adjust grid to 2x3 for 6 models
fig.subplots_adjust(hspace=0.5)  # Add some vertical spacing between subplots

# Flatten the axes array to easily iterate through subplots
axes = axes.flatten()

# Iterate through each model in the models dictionary
for i, (model_name, model) in enumerate(models.items()):
    # Train the model
    model.fit(X_train_scaled, y_train)
    # Make predictions
    y_pred = model.predict(X_test_scaled)
    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    results[model_name] = accuracy
    print(f"{model_name}:\nAccuracy: {accuracy:.4f}\n")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("-" * 50)

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,
                xticklabels=['Class 1', 'Class 2'], yticklabels=['Class 1', 'Class 2'],
                ax=axes[i])  # Assign the plot to the current subplot
    axes[i].set_title(f"Confusion Matrix: {model_name}")
    axes[i].set_xlabel('Predicted Labels')
    axes[i].set_ylabel('True Labels')

# Adjust layout and show the plot
plt.tight_layout()
plt.show()